
from bs4 import BeautifulSoup
import csv
import json

with open('Web Scraping Task with Form.html', 'r', encoding='utf-8') as file:
    soup = BeautifulSoup(file, 'html.parser')

headings = [tag.get_text(strip=True) for tag in soup.find_all(['h1', 'h2'])]
texts = [tag.get_text(strip=True) for tag in soup.find_all(['p', 'li'])]
with open('Extract_Text_Data.csv', 'w', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)
    writer.writerow(['Type', 'Content'])
    for heading in headings:
        writer.writerow(['Heading', heading])
    for text in texts:
        writer.writerow(['Text', text])

table_rows = soup.find('table').find_all('tr')[1:]
table_data = []
for row in table_rows:
    cols = [col.get_text(strip=True) for col in row.find_all('td')]
    table_data.append(cols)
with open('Extract_Table_Data.csv', 'w', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)
    writer.writerow(['Product', 'Price', 'In Stock'])
    writer.writerows(table_data)

cards = soup.select('div[style*="text-align: center;"]')
books_data = []
for card in cards:
    title = card.find('strong').get_text(strip=True)
    price = card.find('p', style='color: green;').get_text(strip=True)
    stock = 'âœ” In stock' in card.text
    button_text = card.find('button').get_text(strip=True)
    books_data.append({
        'Title': title,
        'Price': price,
        'In Stock': stock,
        'Button': button_text
    })
with open('Product_Information.json', 'w', encoding='utf-8') as file:
    json.dump(books_data, file, indent=4)

form_inputs = soup.find('form').find_all(['input', 'select'])
form_data = []
for input_tag in form_inputs:
    name = input_tag.get('name', 'N/A')
    input_type = input_tag.get('type', 'select' if input_tag.name == 'select' else 'N/A')
    default_value = input_tag.get('value', 'N/A')
    form_data.append({'Name': name, 'Type': input_type, 'Default': default_value})
with open('Form_Details.json', 'w', encoding='utf-8') as file:
    json.dump(form_data, file, indent=4)

links = [{'Text': a.get_text(strip=True), 'Href': a['href']} for a in soup.find_all('a', href=True)]
video_links = [{'Video Src': iframe['src']} for iframe in soup.find_all('iframe', src=True)]
with open('Links_and_Multimedia.json', 'w', encoding='utf-8') as file:
    json.dump({'Links': links, 'Videos': video_links}, file, indent=4)

featured_products = []
products = soup.find_all('div', class_='product-card')
for product in products:
    product_id = product['data-id']
    name = product.find('p', class_='name').get_text(strip=True)
    price = product.find('p', class_='price').get_text(strip=True)
    colors = product.find('p', class_='colors').get_text(strip=True).replace('Available colors: ', '')
    featured_products.append({
        'id': product_id,
        'name': name,
        'price': price,
        'colors': colors
    })
with open('Featured_Products.json', 'w', encoding='utf-8') as file:
    json.dump(featured_products, file, indent=4)
